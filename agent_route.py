#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Agent Route3nf **v7**
- æ¯å€‹ phase ä»¥ system_message æ³¨å…¥å°ˆå±¬ promptï¼ˆOPENAI_FUNCTIONS agent éœ€ç”¨ `system_message` è€Œé `prefix`ï¼‰ã€‚
- ä¸å†æŠŠä¸Šä¸€è¼ª ai_reply å›å¯« user_textï¼Œé¿å…è¨Šæ¯éå¢ã€‚
- router â†” phase ä»ä¿æŒç·šæ€§ï¼ˆinitâ†’1nfâ†’â€¦ï¼‰ï¼Œä½†å¯è¼•é¬†æ”¹æˆè¿´åœˆã€‚
"""

import asyncio
import json
import os
import sys
from contextlib import AsyncExitStack
from typing import List, TypedDict
from typing_extensions import Annotated

from dotenv import load_dotenv
from langchain.agents import initialize_agent, AgentType
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph
from langgraph.channels import LastValue
from langchain_mcp_adapters.tools import load_mcp_tools
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()

CONFIG_PATH = os.getenv("CONFIG") or os.path.join(os.path.dirname(__file__), "config.json")

a_stack = AsyncExitStack()

###############################################################################
# Helpers
###############################################################################

def read_cfg():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

class PrettyJSON(json.JSONEncoder):
    def default(self, o):
        if hasattr(o, "content"):
            return {"type": o.__class__.__name__, "content": o.content}
        return super().default(o)

###############################################################################
# LLM
###############################################################################

def get_llm():
    return ChatOpenAI(
        model="gpt-4o",
        temperature=0,
        max_retries=3,
        openai_api_key=os.getenv("OPENAI_API_KEY"),
    )

###############################################################################
# Load MCP tools
###############################################################################

async def load_tools():
    await a_stack.__aenter__()
    tools = []
    for name, info in read_cfg()["mcpServers"].items():
        print(f"ğŸ”— Starting MCP: {name}")
        params = StdioServerParameters(command=info["command"], args=info["args"], env=info["env"])
        r, w = await a_stack.enter_async_context(stdio_client(params))
        sess = await a_stack.enter_async_context(ClientSession(r, w))
        await sess.initialize()
        tools.extend(await load_mcp_tools(sess))
    if not tools:
        print("âŒ MCP tools not loaded"); sys.exit(1)
    return tools

###############################################################################
# Phase prompts
###############################################################################

PHASES = ["init", "1nf", "2nf", "3nf", "sql", "report"]

def router_prompt(msgs: List[dict]) -> str:
    return (
        "ä½ æ˜¯ä¸€ä½è³‡æ–™åº«æ­£è¦åŒ–å°ˆå®¶ã€‚è«‹åœ¨ {'init','1NF','2NF','3NF','sql','report'} ä¸­é¸æ“‡ä¸‹ä¸€æ­¥ä¸¦åªè¼¸å‡ºå–®å­—ã€‚\n\nå°è©±:\n"
        + json.dumps(msgs, ensure_ascii=False)
    )

def phase_prompt(phase: str) -> str:
    base = "ä½ æ˜¯ MySQL å°ˆå®¶åŠ©æ‰‹ï¼Œåªèƒ½ä½¿ç”¨ execute_query å·¥å…·åŸ·è¡Œ SQLã€‚\n"
    details = {
        "init":   "æç¤ºä½¿ç”¨è€…æä¾› raw_table_data (JSON) ä»¥é–‹å§‹ 1NFã€‚",
        "1nf":    "åˆ†æ raw_table_data ä¸¦è½‰æˆ 1NFï¼ˆåƒ…è¼¸å‡º JSONï¼‰ã€‚",
        "2nf":    "ä¾å®Œæ•´ä¸»éµæ‹†é™¤ partial dependency ç”¢ç”Ÿ 2NFï¼ˆåƒ…è¼¸å‡º JSONï¼‰ã€‚",
        "3nf":    "ç§»é™¤å‚³éä¾è³´å®Œæˆ 3NFï¼ˆåƒ…è¼¸å‡º JSONï¼‰ã€‚",
        "sql":    "å°‡ 3NF schema è½‰ç‚º CREATE TABLE DDLï¼Œä¸¦ä»¥ mysql_query åŸ·è¡Œã€‚åƒ…è¼¸å‡º Action JSONã€‚",
        "report": "èªªæ˜æ•´å€‹æµç¨‹ï¼Œä»¥ 'FINAL ANSWER' é–‹é ­ã€‚",
    }
    return base + details.get(phase, "")

###############################################################################
# LangGraph state
###############################################################################

class AgentState(TypedDict):
    user_text: Annotated[str | None, LastValue]
    messages:  Annotated[List[dict], LastValue]
    phase:     Annotated[str, LastValue]

###############################################################################
# Build graph
###############################################################################

async def build_graph():
    llm   = get_llm()
    tools = await load_tools()

    # Router node
    async def router(state: AgentState):
        phase_decision = (await llm.ainvoke(router_prompt(state["messages"]))).content.strip().lower()
        if phase_decision not in PHASES:
            phase_decision = state["phase"]
        return {"phase": phase_decision}

    # Phase node cache
    agents_cache = {}

    async def phase_node(state: AgentState):
        ph = state["phase"]
        if ph not in agents_cache:
            agents_cache[ph] = initialize_agent(
                tools, llm,
                agent=AgentType.OPENAI_FUNCTIONS,
                agent_kwargs={"system_message": phase_prompt(ph)},  # â† é—œéµ
                verbose=False,
            )

        last_input = state["user_text"] or ""
        messages = state["messages"] + [{"role": "user", "content": last_input}]
        ai_reply = await agents_cache[ph].ainvoke({"input": last_input})
        messages.append({"role": "assistant", "content": ai_reply})

        # ç·šæ€§ä¸‹ä¸€éšæ®µ
        next_idx   = PHASES.index(ph) + 1
        next_phase = PHASES[next_idx] if next_idx < len(PHASES) else "report"

        return {"messages": messages, "user_text": None, "phase": next_phase}

    # Wire graph (linear: initâ†’1nfâ†’â€¦)
    g = StateGraph(AgentState)
    g.add_node("router", router)
    prev = "router"
    for p in PHASES:
        g.add_node(p, phase_node)
        g.add_edge(prev, p)
        prev = p
    g.add_edge("report", END)
    g.set_entry_point("router")
    return g.compile()

###############################################################################
# CLI
###############################################################################

async def main():
    graph = await build_graph()
    state: AgentState = {"user_text": None, "messages": [], "phase": "init"}
    print("ğŸš€ DBNormalizeBot route ready. è¼¸å…¥ query æˆ– quitã€‚")
    while True:
        q = input("Query: ").strip()
        if q.lower() == "quit":
            break
        state["user_text"] = q
        state = await graph.ainvoke(state)
        print(json.dumps(state["messages"][-1]["content"], indent=2, ensure_ascii=False, cls=PrettyJSON))
        if isinstance(state["messages"][-1]["content"], str) and state["messages"][-1]["content"].startswith("FINAL ANSWER"):
            state = {"user_text": None, "messages": [], "phase": "init"}
            print("ğŸ”„ é‡æ–°é–‹å§‹â€¦\n")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    finally:
        if a_stack:
            asyncio.run(a_stack.aclose())

